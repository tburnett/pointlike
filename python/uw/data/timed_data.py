"""
Process time data set
see create_timed_data to generate files with times for all 
Extract a single data set around a cone with TimedData
"""

import os, glob, pickle
import healpy
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from astropy.time import Time, TimeDelta
from . import binned_data

mission_start = Time('2001-01-01T00:00:00', scale='utc')
def MJD(met):
    # convert MET to MJD
    return (mission_start+TimeDelta(met, format='sec')).mjd

class TimeInfo(object):
    """Read in, process a file generated by binned_data.ConvertFT1.time_record
    """
    
    def __init__(self, filename):
        d = pickle.load(open(filename)) 
        self.tstart = d['tstart']
        self.df = pd.DataFrame(d['timerec'])
        
    def select(self, l, b, radius=5, nside=1024):
        """create DataFrame with times, band id, distance from center
            
        parameters:
            l,b : position in Galactic 
            radius : cone radius, deg
            nside : for healpy

        returns:
            DataFrame with columns:
                band : from input, energy and event type  
                time : Mission Elapsed Time in s. (double)
                delta : distance from input position (deg, float32)
        """
        df = self.df
        cart = lambda l,b: healpy.dir2vec(l,b, lonlat=True) 
        # use query_disc to get photons within given radius of position
        center = cart(l,b)
        ipix = healpy.query_disc(nside, cart(l,b), np.radians(radius), nest=False)
        incone = np.isin(self.df.hpindex, ipix)

        # times: convert to double, add to start
        t = np.array(df.time[incone],float)+self.tstart

        # convert position info to just distance from center             
        ll,bb = healpy.pix2ang(nside, self.df.hpindex[incone],  nest=False, lonlat=True)
        t2 = np.array(np.sqrt((1.-np.dot(center, cart(ll,bb)))*2), np.float32) 

        return pd.DataFrame(np.rec.fromarrays(
            [df.band[incone], t, np.degrees(t2)], names='band time delta'.split()))

class TimedData(object):
    """Create a data set at a given position
    """
 
    plt.rc('font', size=12)
    
    def __init__(self, position, name='', radius=5, 
            file_pattern='$FERMI/data/P8_P305/time_info/month_*.pkl'):
        """Set up combined data from set of monthly files

        position : l,b in degrees
        name :    string, optional name to describe source
        radius :  float, cone radius for selection
        file_pattern : string for glob use 
        """

        assert hasattr(position, '__len__') and len(position)==2, 'expect position to be (l,b)'
        files = sorted(glob.glob(os.path.expandvars(file_pattern)))
        assert len(files)>0, 'No files found using pattern {}'.format(file_pattern)
        self.name = name
        gbtotal = np.array([os.stat(filename).st_size for filename in files]).sum()/2**30
        print  'Opening {} files, with {} GB total'.format(len(files), gbtotal)

        dflist=[]
        for filename in files:
            dflist.append(TimeInfo(filename).select(*position))
            print '.',
        self.df = pd.concat(dflist)
        print 'Selected {} photons'.format(len(self.df))

    def plot_time(self, delta_max=2, delta_t=1, xlim=None):
        """
        """
        df = self.df

        t = timed_data.MJD(df.time)
        ta,tb=t[0],t[-1]
        Nbins = int((tb-ta)/float(delta_t))

        fig,ax= plt.subplots(figsize=(15,5))
        hkw = dict(bins = np.linspace(ta,tb,Nbins), histtype='step')
        ax.hist(t, label='E>100 MeV', **hkw)
        ax.hist(t[(df.delta<delta_max) & (df.band>0)], label='delta<{} deg'.format(delta_max), **hkw);
        ax.set(xlabel=r'$\mathsf{MJD}$', ylabel='counts per {:.0f} day'.format(delta_t))
        if xlim is not None: ax.set(xlim=xlim)
        ax.legend()
        ax.set_title('{} counts vs. time'.format(self.name))

    def plot_delta(self, cumulative=False, squared=True):
        plt.rc('font', size=12)
        df = self.df
        fig,ax = plt.subplots(figsize=(6,6))
        x = df.delta**2 if squared else df.delta
        hkw = dict(bins=np.linspace(0, 25 if squared else 5, 100), histtype='step',lw=2,cumulative=cumulative)
        ax.hist(x, label='E>100 MeV', **hkw)
        ax.hist(x[df.band>8], label='E>1 GeV', **hkw)
        ax.set(yscale='log', xlabel='delta**2 [deg^2]' if squared else 'delta [deg]', 
            ylabel='cumulative counts' if cumulative else 'counts'); 
        ax.legend(loc='upper left' if cumulative else 'upper right');

def create_timed_data(
        monthly_ft1_files='/afs/slac/g/glast/groups/catalog/P8_P305/zmax105/*.fits',
        outfolder='$FERMI/data/P8_P305/time_info/',
        overwrite=False,
        test=False, 
        verbose=1):
    """
    """
    files=sorted(glob.glob(monthly_ft1_files))
    assert len(files)>0, 'No ft1 files found at {}'.format(monthly_ft1_files)
    gbtotal = np.array([os.stat(filename).st_size for filename in files]).sum()/2**30
    if verbose>0:
        print '{} monthly FT1 files found at {}\n\t {} GB total'.format(len(files), monthly_ft1_files, gbtotal)
    outfolder = os.path.expandvars(outfolder)
    if not os.path.exists(outfolder):
        os.makedirs(outfolder)
    os.chdir(outfolder)  
    if verbose>0:
        print 'Writing time files to folder {}\n\toverwrite={}'.format(outfolder, overwrite) 
    for filename in files:
        m = filename.split('_')[-2]
        outfile = 'month_{}.pkl'.format(m)
        if not overwrite and os.path.exists(outfile) :
            if verbose>1:
                print 'exists: {}'.format(outfile)
            else: 
                print '.',
            continue

        tr = binned_data.ConvertFT1(filename).time_record()
        if not test:
            if verbose>1:
                print 'writing {}'.format(outfile),
            elif verbose>0:
                print '+',
            pickle.dump(tr, open(outfile, 'wr'))
        else:            
            if verbose>0:
                print 'Test: would have written {}'.format(outfile)
    # check how many exist
    files=sorted(glob.glob(outfolder+'/*.pkl'))
    gbtotal = np.array([os.stat(filename).st_size for filename in files]).sum()/float(2**30)
    print '\nThere are {} timed data files, {:.1f} GB total'.format(len(files), gbtotal)
